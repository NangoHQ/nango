---
title: 'AI Tool Calling'
sidebarTitle: 'AI Tool Calling'
description: 'Connect your AI agents and workflows to the real world.'
---

Nango makes it simple to authorize APIs and call external tools from any LLM or AI framework.


## When should you use Nango for AI tool calling?

Use Nango whenever your AI needs to **take action** in the real world.

- You want your agent or LLM workflow to create, update, or fetch data from real APIs.
- You want to avoid building your own auth, tool infrastructure, or execution sandbox.
- You need reliability, observability, and scalability for tool calls.

### Common examples

- Letting an AI agent create or update a CRM opportunity.
- Having a chatbot fetch live context from Notion, Linear, or HubSpot.
- Running automations triggered by an LLM (e.g., "schedule a meeting" or "create a task").

<Tip>
For RAG-style use cases where data must be replicated locally, use [Syncs](/guides/use-cases/syncs) instead.
</Tip>



## Key facts

- **Framework-agnostic:** Works with any agentic or LLM framework (or none at all).  
  Compatible with OpenAI Agents SDK, Vercel AI SDK, LangChain, LlamaIndex, and more.
- **Unified API auth:** Securely authorize access to third-party APIs via Nango’s [Auth](/guides/use-cases/api-auth) system.  
  You can even surface [Connect Links](/guides/platform/connect-links) directly in your chat UI for user-driven OAuth.
- **Tool execution via Actions:**  
  Tools in Nango are powered by [Actions](/guides/use-cases/actions).  
  - Use prebuilt templates for common tools (e.g. “Create Lead”, “Send Message”).  
  - Or build your own Actions for full control and reliability.
- **MCP-compatible:**  
  - Expose your integrations through Nango’s built-in MCP Server.  
  - Follow our [implement the MCP Server](/implementation-guides/mcp-server/implement-mcp-server) guide.
  - Check out the [MCP server demo](https://www.youtube.com/embed/80W3AZMM9KY)
  - Connect to existing official MCP servers (e.g. Notion, Linear) with Nango's MCP auth.
- **Secure, scalable, and observable:**  
  - Tool code runs in sandboxed, elastic environments.  
  - Cold start under 100 ms — fast enough for human-in-the-loop workflows.  
  - Logs and metrics help monitor and optimize your tool calls.


## How it works

1. **Authorize**: Your users connect their accounts via Nango.  
2. **Expose tools**: You configure which Actions your LLM or agent can call.  
3. **Call tools**: The agent invokes Nango-hosted Actions via API or MCP.  
4. **Observe & optimize**: Track results and performance in Nango’s [Logs](/guides/platform/logs).


## Implementation guides

Nango works with any framework or SDK that supports tool calling.

| Framework | Example Guide |
|------------|----------------|
| [OpenAI Agents SDK](#) | Using Nango Actions in an OpenAI Agent |
| [Vercel AI SDK](#) | Exposing Nango tools to a Vercel AI route |
| [Anthropic Claude SDK](#) | Calling Nango Actions from a Claude agent |
| [LangChain](#) | Adding Nango Actions as tools in LangChain |
| [LlamaIndex](#) | Integrating Nango tools in retrieval pipelines |
| [Transformers Agents](#) | Configuring Nango endpoints for Transformers |
| [Semantic Kernel](#) | Authorizing API access with Nango |
| [CrewAI](#) | Delegating tool execution to Nango |
| [Autogen](#) | Handling tool authorization via Nango Connect Links |
| [MCP](/implementation-guides/mcp-server/implement-mcp-server) | Use Nango's MCP server to power AI tools |
